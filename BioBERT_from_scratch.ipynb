{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BioBERT_from_scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpo/RGtldNh2u6o0p6YeG2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3317dab776d48a294a09bbdfbbc2932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65b0d66cceae422391f579e6712358a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92489e2143f94e5286f2bdfbc282f303",
              "IPY_MODEL_dfa7d5862b2542cead3ae38d4ac565d8"
            ]
          }
        },
        "65b0d66cceae422391f579e6712358a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92489e2143f94e5286f2bdfbc282f303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_58709cd9521845508f34432b2f3c8eba",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 385,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 385,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e209459c8594f63a470f693ec5fb326"
          }
        },
        "dfa7d5862b2542cead3ae38d4ac565d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0ce6a06ed084c658e75e298a224248c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 385/385 [00:02&lt;00:00, 180B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e6b0802c6434b6cb14b168b6bd249a1"
          }
        },
        "58709cd9521845508f34432b2f3c8eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e209459c8594f63a470f693ec5fb326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0ce6a06ed084c658e75e298a224248c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e6b0802c6434b6cb14b168b6bd249a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afdccf8400ad49d785ada35019e5de05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5edd11ecf1bf451891e9cb8fccdc3d82",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0971d8b1e5f045e5b0f173495361340d",
              "IPY_MODEL_519a804c64944246a2f77e31babd1860"
            ]
          }
        },
        "5edd11ecf1bf451891e9cb8fccdc3d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0971d8b1e5f045e5b0f173495361340d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a6952697309e4f689cbee93269a6cfa3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4a25b0273614645b3b780d2fd58c95c"
          }
        },
        "519a804c64944246a2f77e31babd1860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e89295ed730c4fbbbd8f5cc8ecaf83f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:01&lt;00:00, 146kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_167776241c144837ab744b03791bed6d"
          }
        },
        "a6952697309e4f689cbee93269a6cfa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4a25b0273614645b3b780d2fd58c95c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e89295ed730c4fbbbd8f5cc8ecaf83f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "167776241c144837ab744b03791bed6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcf682837ec94de4a8ea3c1fda2efa43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1878a75209784d2ba5ea52af671780bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3d6f8f58dce4a45a094f394d29b81da",
              "IPY_MODEL_7367d5d7ca2f4a78b0b88cfaef863a9d"
            ]
          }
        },
        "1878a75209784d2ba5ea52af671780bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3d6f8f58dce4a45a094f394d29b81da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_46db7b640f224ebbb65124e7f400a5de",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435778770,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435778770,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_380e44b397a84ef0afff2adfb9d814fc"
          }
        },
        "7367d5d7ca2f4a78b0b88cfaef863a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be43f0d602ad4f82b2c431d711bf2085",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:14&lt;00:00, 29.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b01161632110442da8712b53e3742ec1"
          }
        },
        "46db7b640f224ebbb65124e7f400a5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "380e44b397a84ef0afff2adfb9d814fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be43f0d602ad4f82b2c431d711bf2085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b01161632110442da8712b53e3742ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnaks97/Natural-Language-Inference/blob/master/BioBERT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsFz3AqlUoxQ",
        "outputId": "f42febdf-c650-4888-c11e-d95d30800c19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.6-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=1a9a4be2ccb24057817c98d1b44f7184f8a0f4836ad0c57267a4348e494c8fa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n",
            "Collecting cloud-tpu-client==0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting torch-xla==1.6\n",
            "\u001b[?25l  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.6-cp36-cp36m-linux_x86_64.whl (133.2MB)\n",
            "\u001b[K     |████████████████████████████████| 133.2MB 96kB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.6)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (50.3.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.1.1)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.52.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client, torch-xla\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 torch-xla-1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS_vE0fBVA1B",
        "outputId": "d8bf23ae-1286-45f6-a3cc-3f7e1e39a159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "drive.mount('/content/drive')\n",
        "# If repo already cloned in drive\n",
        "os.chdir('drive/My Drive/Natural-Language-Inference')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvUjDsGKVDcR"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import AutoModel, AutoModelForSequenceClassification, AutoTokenizer, AdamW, BertForSequenceClassification, BertTokenizer\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from collections import defaultdict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxOhHjUpVOhI",
        "outputId": "7a8dcf03-c5ab-4c9a-dccd-1949e699d3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278,
          "referenced_widgets": [
            "f3317dab776d48a294a09bbdfbbc2932",
            "65b0d66cceae422391f579e6712358a5",
            "92489e2143f94e5286f2bdfbc282f303",
            "dfa7d5862b2542cead3ae38d4ac565d8",
            "58709cd9521845508f34432b2f3c8eba",
            "9e209459c8594f63a470f693ec5fb326",
            "d0ce6a06ed084c658e75e298a224248c",
            "8e6b0802c6434b6cb14b168b6bd249a1",
            "afdccf8400ad49d785ada35019e5de05",
            "5edd11ecf1bf451891e9cb8fccdc3d82",
            "0971d8b1e5f045e5b0f173495361340d",
            "519a804c64944246a2f77e31babd1860",
            "a6952697309e4f689cbee93269a6cfa3",
            "a4a25b0273614645b3b780d2fd58c95c",
            "e89295ed730c4fbbbd8f5cc8ecaf83f5",
            "167776241c144837ab744b03791bed6d",
            "bcf682837ec94de4a8ea3c1fda2efa43",
            "1878a75209784d2ba5ea52af671780bc",
            "b3d6f8f58dce4a45a094f394d29b81da",
            "7367d5d7ca2f4a78b0b88cfaef863a9d",
            "46db7b640f224ebbb65124e7f400a5de",
            "380e44b397a84ef0afff2adfb9d814fc",
            "be43f0d602ad4f82b2c431d711bf2085",
            "b01161632110442da8712b53e3742ec1"
          ]
        }
      },
      "source": [
        "model_name = 'emilyalsentzer/Bio_ClinicalBERT' # 'bert-base-uncased\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, force_download=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3317dab776d48a294a09bbdfbbc2932",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afdccf8400ad49d785ada35019e5de05",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcf682837ec94de4a8ea3c1fda2efa43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435778770.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HguXrppVm_t"
      },
      "source": [
        "train_df = pd.read_csv('Data/mli_train_v1.csv')\n",
        "val_df = pd.read_csv('Data/mli_dev_v1.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsWB_BJbVuW8"
      },
      "source": [
        "train_pre, train_hyp, train_labels = train_df['premise'].tolist(), train_df['hypothesis'].tolist(), train_df['gold_label'].tolist()\n",
        "val_pre, val_hyp, val_labels = val_df['premise'].tolist(), val_df['hypothesis'].tolist(), val_df['gold_label'].tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3jij4OuVxLW"
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "train_labels = le.transform(train_labels)\n",
        "val_labels = le.transform(val_labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu5c-X-bV2Nu",
        "outputId": "13c12ad9-c7a5-4438-d723-0ee7945fd9f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for pre, hyp, encoded_label, label in zip(train_pre[:10], train_hyp[:10], train_labels[:10], le.inverse_transform(train_labels[:10])):\n",
        "  print(pre + ' ||||| ' + hyp + ' <=======> ' + str(encoded_label) + ' = '+ str(label))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labs were notable for cr 1.7 (baseline 0.5 per old records) and lactate 2.4. ||||| patient has elevated cr <=======> 1 = entailment\n",
            "labs were notable for cr 1.7 (baseline 0.5 per old records) and lactate 2.4. ||||| patient has normal cr <=======> 0 = contradiction\n",
            "labs were notable for cr 1.7 (baseline 0.5 per old records) and lactate 2.4. ||||| patient has elevated bun <=======> 2 = neutral\n",
            "nystagmus and twiching of r arm was noted. ||||| the patient had abnormal neuro exam. <=======> 1 = entailment\n",
            "nystagmus and twiching of r arm was noted. ||||| the patient has a normal neuro exam. <=======> 0 = contradiction\n",
            "nystagmus and twiching of r arm was noted. ||||| the patient has an acute stroke. <=======> 2 = neutral\n",
            "the patient was seen by his primary care physician after he had complained of a one-week history of dyspnea on exertion and jaw tightness. ||||| the patient has symptoms of a chf exacerbation. <=======> 1 = entailment\n",
            "the patient was seen by his primary care physician after he had complained of a one-week history of dyspnea on exertion and jaw tightness. ||||| the patient has no symptoms. <=======> 0 = contradiction\n",
            "the patient was seen by his primary care physician after he had complained of a one-week history of dyspnea on exertion and jaw tightness. ||||| the patient has has coronary artery disease. <=======> 2 = neutral\n",
            "at plains regional medical center hospital the patient was experiencing 10 out of 10 chest pain and received nitropaste two inches, three sublingual nitroglycerins, morphine 4 mg intravenously, lopressor 5 mg intravenously. ||||| the patient is being treated with medications used to treat acute coronary syndrome. <=======> 1 = entailment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek-sCelJV4EU",
        "outputId": "9eb6ac69-0ce9-4265-a6a6-5aa2ceb4d865",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for pre, hyp, encoded_label, label in zip(val_pre[:10], val_hyp[:10], val_labels[:10], le.inverse_transform(val_labels[:10])):\n",
        "  print(pre + ' ||||| ' + hyp + ' <=======> ' + str(encoded_label) + ' = '+ str(label))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no history of blood clots or dvts, has never had chest pain prior to one week ago. ||||| patient has angina <=======> 1 = entailment\n",
            "no history of blood clots or dvts, has never had chest pain prior to one week ago. ||||| patient has had multiple pes <=======> 0 = contradiction\n",
            "no history of blood clots or dvts, has never had chest pain prior to one week ago. ||||| patient has cad <=======> 2 = neutral\n",
            "over the past week pta he has been more somnolent and difficult to arrouse. . ||||| he has been less alert over the past week <=======> 1 = entailment\n",
            "over the past week pta he has been more somnolent and difficult to arrouse. . ||||| over the past week he has been alert and oriented <=======> 0 = contradiction\n",
            "over the past week pta he has been more somnolent and difficult to arrouse. . ||||| he is disorientated and complains of weakness <=======> 2 = neutral\n",
            "copd/asthma: spirometry (4/3393) fvc 2.48 (67%), fev1 1.96 (68%), fev1/fvc 101%, dlco (3/3392) 51%, lung vol (3/3392): tlc 64%, frc 48%, rv 49%, erv 47%, multiple admissions, intubation x 1 3391 3. ||||| the patient has a history of obstructive lung disease <=======> 1 = entailment\n",
            "copd/asthma: spirometry (4/3393) fvc 2.48 (67%), fev1 1.96 (68%), fev1/fvc 101%, dlco (3/3392) 51%, lung vol (3/3392): tlc 64%, frc 48%, rv 49%, erv 47%, multiple admissions, intubation x 1 3391 3. ||||| the patient has normal lungs <=======> 0 = contradiction\n",
            "copd/asthma: spirometry (4/3393) fvc 2.48 (67%), fev1 1.96 (68%), fev1/fvc 101%, dlco (3/3392) 51%, lung vol (3/3392): tlc 64%, frc 48%, rv 49%, erv 47%, multiple admissions, intubation x 1 3391 3. ||||| the patient is a smoker <=======> 2 = neutral\n",
            "during hospitalization, patient became progressively more dyspnic requiring bipap and then a nrb. ||||| the patient is in respiratory failure. <=======> 1 = entailment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJA-fD8UvGNl",
        "outputId": "ffd650b4-463e-46a1-ea44-a45562afd406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in train_hyp:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tZ8akXTvMwt",
        "outputId": "598d1593-347f-41a5-8c33-cacddf8b460f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 512]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdub8bVFxGjm",
        "outputId": "26093a07-57f5-49ba-bd5f-e76d998da532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max(token_lens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HBYQ7gi2qMi",
        "outputId": "3a9aba69-7d4e-4067-fe54-fd8d14bc71df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(tokenizer.encode_plus(\"This is sentence two\", \"This is sentence 2 of a very mauch lonegr length lets see\", max_length=30, padding='max_length'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1142, 1110, 5650, 1160, 102, 1142, 1110, 5650, 123, 1104, 170, 1304, 12477, 9827, 14936, 1403, 1197, 2251, 11446, 1267, 102, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgmc0XTQyWBT"
      },
      "source": [
        "enc = tokenizer.encode_plus(\"This is sentence one of lenght approx. 23\", \"This is sentence two\", max_length=5, padding='max_length')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTOKEeYt1MFF",
        "outputId": "b5992f15-d36d-4953-d836-1fb85001fb02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(enc['input_ids'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY-V-HRkyzMp",
        "outputId": "877ffb08-4180-4644-9739-094c5e71c160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(enc['input_ids'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'this',\n",
              " 'is',\n",
              " 'sentence',\n",
              " 'one',\n",
              " 'of',\n",
              " 'le',\n",
              " '##ng',\n",
              " '##ht',\n",
              " 'approx',\n",
              " '.',\n",
              " '23',\n",
              " '[SEP]',\n",
              " 'this',\n",
              " 'is',\n",
              " 'sentence',\n",
              " 'two',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF4gzsCrWipY"
      },
      "source": [
        "class MedNLIDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, premise_sent, hypothesis_sent, labels, tokenizer, max_len=512):\n",
        "    self.premise_sent = premise_sent\n",
        "    self.hypothesis_sent = hypothesis_sent\n",
        "    self.labels = labels\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    premise = self.premise_sent[idx]\n",
        "    hypothesis = self.hypothesis_sent[idx]\n",
        "    label = self.labels[idx]\n",
        "    encoding = tokenizer.encode_plus(premise, hypothesis, add_special_tokens=True, return_token_type_ids=True, return_attention_mask=True, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    #print('After encoding: ', encoding)\n",
        "    #print(\"Processing: \", idx)\n",
        "    #print(encoding['input_ids'].shape, encoding['attention_mask'].shape, encoding['token_type_ids'].shape)\n",
        "    data = {\n",
        "      'premise': premise,\n",
        "      'hypothesis': hypothesis,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "      'labels': torch.tensor(label, dtype=torch.long)\n",
        "    }\n",
        "    return data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh6uEeJVddAi"
      },
      "source": [
        "def create_data_loader(premise_sent, hypothesis_sent, labels, tokenizer, batch_size, max_len):\n",
        "  ds = MedNLIDataset(\n",
        "    premise_sent=premise_sent,\n",
        "    hypothesis_sent=hypothesis_sent,\n",
        "    labels=labels,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "    #collate_fn=lambda x:x\n",
        "  )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMiY99uxeNoZ"
      },
      "source": [
        "BATCH_SIZE=16\n",
        "MAX_LEN = 160"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WtdPfb3eg58"
      },
      "source": [
        "train_data_loader = create_data_loader(train_pre, train_hyp, train_labels, tokenizer, BATCH_SIZE, MAX_LEN)\n",
        "val_data_loader = create_data_loader(val_pre, val_hyp, val_labels, tokenizer, BATCH_SIZE, MAX_LEN)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_doe6G5Ve8Y6",
        "outputId": "b9bc6a6b-9fd5-43e4-fca0-34eac519fafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['premise', 'hypothesis', 'input_ids', 'attention_mask', 'token_type_ids', 'labels'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIdAqHz3fAnt",
        "outputId": "67923084-fe5a-49d5-a1a3-62515790e2cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['labels'].shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKlSq-Wu_wsc",
        "outputId": "b05fd72e-a4da-44b2-e44c-19043f17e237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "#DEVICE = xm.xla_device()\n",
        "DEVICE"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAwAX0s1ADRU",
        "outputId": "1c58c6b8-64a1-4466-cbeb-b01bde8ead1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.to(DEVICE)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lpv02yKAc4t",
        "outputId": "14e6b516-5515-4336-8956-e6996ab26596",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_ids = data['input_ids'].to(DEVICE)\n",
        "attention_mask = data['attention_mask'].to(DEVICE)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qycFhkzvA1WV"
      },
      "source": [
        "from torch.nn.functional import softmax\n",
        "model.aux_logits=False"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1bBU1BdAkpi",
        "outputId": "ae30748a-126d-4bcb-fafd-93622bb8539e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "F.softmax(model(input_ids, attention_mask)[0], dim=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1950, 0.3523, 0.4527],\n",
              "        [0.1953, 0.3538, 0.4509],\n",
              "        [0.2077, 0.3650, 0.4273],\n",
              "        [0.2706, 0.3847, 0.3447],\n",
              "        [0.2837, 0.4148, 0.3015],\n",
              "        [0.2754, 0.4048, 0.3198],\n",
              "        [0.2473, 0.3747, 0.3780],\n",
              "        [0.2508, 0.3737, 0.3755],\n",
              "        [0.2453, 0.3821, 0.3726],\n",
              "        [0.2424, 0.4080, 0.3496],\n",
              "        [0.2384, 0.3927, 0.3689],\n",
              "        [0.2408, 0.3954, 0.3638],\n",
              "        [0.2474, 0.4085, 0.3441],\n",
              "        [0.2612, 0.4355, 0.3033],\n",
              "        [0.2537, 0.4063, 0.3400],\n",
              "        [0.2405, 0.3952, 0.3643]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YekIawRKBK13"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnIO9kjUC1Lv"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=100,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(DEVICE)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYUvVAEPDBxJ"
      },
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for i,d in enumerate(data_loader):\n",
        "    print(i)\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    labels = d[\"labels\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )[0]\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == labels)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgnxRIEQDTUI"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"labels\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )[0]\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, labels)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == labels)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqG1IHZPEXkk",
        "outputId": "3b4f6a93-40b2-417b-9618-b3fdf6fe88bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    DEVICE, \n",
        "    scheduler, \n",
        "    len(train_labels)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    DEVICE, \n",
        "    len(val_labels)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), './results/best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8448a9b90165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nhistory = defaultdict(list)\\nbest_accuracy = 0\\n\\nfor epoch in range(EPOCHS):\\n\\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\\n  print('-' * 10)\\n\\n  train_acc, train_loss = train_epoch(\\n    model,\\n    train_data_loader,    \\n    loss_fn, \\n    optimizer, \\n    DEVICE, \\n    scheduler, \\n    len(train_labels)\\n  )\\n\\n  print(f'Train loss {train_loss} accuracy {train_acc}')\\n\\n  val_acc, val_loss = eval_model(\\n    model,\\n    val_data_loader,\\n    loss_fn, \\n    DEVICE, \\n    len(val_labels)\\n  )\\n\\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\\n  print()\\n\\n  history['train_acc'].append(train_acc)\\n  history['train_loss'].append(train_loss)\\n  history['val_acc'].append(val_acc)\\n  history['val_loss'].append(val_loss)\\n\\n  if val_acc > best_accuracy:\\n    torch.save(model.state_dict(), './results/best_model_state.bin')\\n    best_accuracy = val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7DnV6pZFS38"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}